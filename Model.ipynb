{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 첫번째 모델\n",
    "### CNN+LSTM\n",
    "- input shape: (image 갯수, frame 수, image크기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import models, layers\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(keras.Model):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        self.BZ = input_shape[0]\n",
    "        self.frame = input_shape[1]\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(32, kernel_size=(5,5), activation= 'relu', input_shape = input_shape)\n",
    "        self.conv2 = layers.Conv2D(64, kernel_size=(5,5), activation= 'relu')\n",
    "        self.conv3 = layers.Conv2D(128, kernel_size=(5,5), activation= 'relu')\n",
    "        self.lstm = layers.LSTM(256, return_sequences = False)\n",
    "        #self.lstm2 = layers.LSTM(128, return_sequences = True)\n",
    "        #self.lstm3= layers.LSTM(256, return_sequences = False)\n",
    "        self.dense = layers.Dense(16, activation = 'softmax')\n",
    "        #self.max_pool= layers.MaxPooling2D(pool_size= (2,2))\n",
    "        \n",
    "        #self.flatten = layers.Flatten()\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = tf.reshape(x,(self.BZ, self.frame, -1))\n",
    "        x = self.lstm(x)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "[1, 4, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 13, 1, 1, 1, 1, 1, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 20, 64, 64, 3)\n",
    "x = tf.random.normal(input_shape)\n",
    "model = CNN_LSTM(input_shape, 16)\n",
    "y = model(x)\n",
    "label = []\n",
    "for i in range(len(y)):\n",
    "    label.append(np.argmax(y[i]))\n",
    "print(len(label))\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 두번째 모델\n",
    "### Deep Layered CNN+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deep_CNN_LSTM(keras.Model):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super(deep_CNN_LSTM, self).__init__()\n",
    "        self.BZ = input_shape[0]\n",
    "        self.frame = input_shape[1]\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(32, kernel_size=(5,5), activation= 'relu', input_shape = input_shape)\n",
    "        self.conv2 = layers.Conv2D(64, kernel_size=(5,5), activation= 'relu')\n",
    "        self.conv3 = layers.Conv2D(128, kernel_size=(5,5), activation= 'relu')\n",
    "        #self.lstm = layers.LSTM(256, return_sequences = False)\n",
    "        self.bilstm = layers.Bidirectional(layers.LSTM(256), merge_mode = 'concat')\n",
    "        #self.lstm2 = layers.LSTM(128, return_sequences = True)\n",
    "        #self.lstm3= layers.LSTM(256, return_sequences = False)\n",
    "        self.dense = layers.Dense(16, activation = 'softmax')\n",
    "        self.max_pool= layers.MaxPooling2D(pool_size= (2,2))\n",
    "        self.dropout = layers.Dropout(0.2)\n",
    "        #self.flatten = layers.Flatten()\n",
    "    \n",
    "    def call(self, input):\n",
    "        fm = []\n",
    "        for x in input:\n",
    "            x = self.conv1(x)\n",
    "            x = self.dropout(self.max_pool(x))\n",
    "            x = self.conv2(x)\n",
    "            x = self.dropout(self.max_pool(x))\n",
    "            x = self.conv3(x)\n",
    "            x = self.dropout(self.max_pool(x))\n",
    "            fm.append(x)\n",
    "        x = tf.reshape(fm,(self.BZ, self.frame, -1))\n",
    "        print(x.shape)\n",
    "            \n",
    "        x = self.bilstm(x)\n",
    "        print(x.shape)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 20, 2048)\n",
      "(32, 512)\n",
      "32\n",
      "[6, 4, 4, 6, 6, 6, 6, 6, 6, 4, 4, 6, 6, 6, 6, 6, 6, 4, 4, 6, 4, 6, 4, 4, 6, 6, 6, 6, 6, 4, 6, 4]\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 20, 64, 64, 3)\n",
    "x = tf.random.normal(input_shape)\n",
    "model = deep_CNN_LSTM(input_shape, 16)\n",
    "y = model(x)\n",
    "label = []\n",
    "for i in range(len(y)):\n",
    "    label.append(np.argmax(y[i]))\n",
    "print(len(label))\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 세번째 모델\n",
    "### Pretrained VGG-16(ImageNet) + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "class VGG_LSTM(keras.Model):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super(VGG_LSTM, self).__init__()\n",
    "        self.BZ = input_shape[0]\n",
    "        self.frame = input_shape[1]\n",
    "        \n",
    "        self.vgg = VGG16(weights = 'imagenet', include_top = False, input_shape = (input_shape[2], input_shape[3], input_shape[4]))\n",
    "        self.vgg.trainable = False\n",
    "            \n",
    "        #self.lstm = layers.LSTM(256, return_sequences = False)\n",
    "        self.bilstm = layers.Bidirectional(layers.LSTM(256), merge_mode = 'concat')\n",
    "        #self.lstm2 = layers.LSTM(128, return_sequences = True)\n",
    "        #self.lstm3= layers.LSTM(256, return_sequences = False)\n",
    "        self.dense = layers.Dense(16, activation = 'softmax')\n",
    "        self.max_pool= layers.MaxPooling2D(pool_size= (2,2))\n",
    "        self.dropout = layers.Dropout(0.2)\n",
    "        #self.flatten = layers.Flatten()\n",
    "    \n",
    "    def call(self, input):\n",
    "        print(input.shape)\n",
    "        fm = []\n",
    "        for x in input:\n",
    "            x = self.vgg(x)\n",
    "            #print(x.shape)\n",
    "            fm.append(x)\n",
    "        x = tf.reshape(fm,(self.BZ, self.frame, -1)) # (32, 20, 2048)\n",
    "        x = self.bilstm(x)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 20, 64, 64, 3)\n",
      "32\n",
      "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 20, 64, 64, 3)\n",
    "x = tf.random.normal(input_shape)\n",
    "model = VGG_LSTM(input_shape, 16)\n",
    "y = model(x)\n",
    "label = []\n",
    "for i in range(len(y)):\n",
    "    label.append(np.argmax(y[i]))\n",
    "print(len(label))\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네번째 모델\n",
    "### Fine-Tuned VGG-16 + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "class VGG_LSTM(keras.Model):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super(VGG_LSTM, self).__init__()\n",
    "        self.BZ = input_shape[0]\n",
    "        self.frame = input_shape[1]\n",
    "        \n",
    "        self.vgg = VGG16(weights = 'imagenet', include_top = False, input_shape = (input_shape[2], input_shape[3], input_shape[4]))\n",
    "        self.vgg.trainable = True\n",
    "            \n",
    "        #self.lstm = layers.LSTM(256, return_sequences = False)\n",
    "        self.bilstm = layers.Bidirectional(layers.LSTM(256), merge_mode = 'concat')\n",
    "        #self.lstm2 = layers.LSTM(128, return_sequences = True)\n",
    "        #self.lstm3= layers.LSTM(256, return_sequences = False)\n",
    "        self.dense = layers.Dense(16, activation = 'softmax')\n",
    "        self.max_pool= layers.MaxPooling2D(pool_size= (2,2))\n",
    "        self.dropout = layers.Dropout(0.2)\n",
    "        #self.flatten = layers.Flatten()\n",
    "    \n",
    "    def call(self, input):\n",
    "        print(input.shape)\n",
    "        fm = []\n",
    "        for x in input:\n",
    "            x = self.vgg(x)\n",
    "            #print(x.shape)\n",
    "            fm.append(x)\n",
    "        x = tf.reshape(fm,(self.BZ, self.frame, -1)) # (32, 20, 2048)\n",
    "        x = self.bilstm(x)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 20, 64, 64, 3)\n",
      "32\n",
      "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 20, 64, 64, 3)\n",
    "x = tf.random.normal(input_shape)\n",
    "model = VGG_LSTM(input_shape, 16)\n",
    "y = model(x)\n",
    "label = []\n",
    "for i in range(len(y)):\n",
    "    label.append(np.argmax(y[i]))\n",
    "print(len(label))\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BZ = 32\n",
    "frame_size = 20\n",
    "input_shape = (BZ, frame_size, 64, 64, 3)\n",
    "num_classes = 16\n",
    "model = CNN_LSTM(input_shape, num_classes)\n",
    "\n",
    "loss = keras.losses.CategoricalCrossentropy(from_logits = True)\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        test_loss.reset_states()\n",
    "        test_accuracy.reset_states()\n",
    "        \n",
    "        for images, label in train_dataset:\n",
    "            y_hat = model(images)\n",
    "            y = []\n",
    "            for i in range(len(y_hat)):\n",
    "                y.append(np.argmax(y_hat[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "## dataset\n",
    "x = np.random.random((32, 20, 64, 64, 3))\n",
    "y = np.random.randint((32,))\n",
    "#model.fit(x,epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JolpJJang",
   "language": "python",
   "name": "jolpjjang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
