{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aggregate-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from PyQt5.QtCore import *\n",
    "from PyQt5.QtGui import *\n",
    "from threading import Thread\n",
    "import time\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "class Video(QObject):\n",
    "    sendImage = pyqtSignal(QImage)\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    \n",
    "    def __init__(self, widget, size):\n",
    "        super().__init__()\n",
    "        self.widget = widget\n",
    "        self.size = size\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "        self.sendImage.connect(self.widget.recvImage)\n",
    "        self.x_data = np.shape(4)\n",
    "        \n",
    "    def getInput(self):\n",
    "        return self.x_data\n",
    "    \n",
    "    def startCam(self):\n",
    "        try:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "        except Exception as e:\n",
    "            print('Cam error: ', e)\n",
    "        else:\n",
    "            self.bThread = True\n",
    "            self.thread = Thread(target=self.threadFunc)\n",
    "            self.thread.start()\n",
    "\n",
    "    def stopCam(self):\n",
    "        self.bThread = False\n",
    "        boepn = False\n",
    "        try:\n",
    "            bopen = self.cap.isOpened()\n",
    "            ## predict 객체에게 x_data 넘기는 구간 ##\n",
    "        except Exception as e:\n",
    "            print('Error cam not opened')\n",
    "        else:\n",
    "            self.cap.release()\n",
    "            \n",
    "    def shape_to_np(shape, dtype=\"int\"):\n",
    "        #initialize the list of (x, y)-coordinates\n",
    "        coords = np.zeros((20, 2), dtype=dtype)\n",
    "        # for only lip landmarks\n",
    "        n = 0\n",
    "        for i in range(48, shape.num_parts):\n",
    "            coords[n] = (shape.part(i).x, shape.part(i).y)\n",
    "            n += 1\n",
    "            \n",
    "        # return the list of (x, y)-coordinates\n",
    "        return coords\n",
    "            \n",
    "    def threadFunc(self):\n",
    "        while self.bThread:\n",
    "            isFirst = True\n",
    "            ok, frame = self.cap.read()\n",
    "            if ok:\n",
    "                image = cv2.resize(frame, dsize=(640, 480), interpolation = cv2.INTER_AREA)\n",
    "                #img = image.copy()\n",
    "                img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                face_detector = self.detector(img_gray, 1)\n",
    "                if len(face_detector) == 0:\n",
    "                    print(\"***************No face Detected*************\")\n",
    "                \n",
    "                for face in face_detector:\n",
    "                    landmarks = self.predictor(image, face)\n",
    "                    landmarks = shape_to_np(landmarks)\n",
    "                    # select center of mouth\n",
    "                    x_list = [x[0] for x in landmarks]\n",
    "                    y_list = [y[0] for y in landmarks]\n",
    "                    self.x = sum(x_list)//20\n",
    "                    self.y = sum(y_list)//20\n",
    "                    \n",
    "                # create image\n",
    "                dst = image[self.y-50:self.y+50, self.x-100:self.x+100].copy()\n",
    "                img_tensor = img_to_array(dst)\n",
    "                img_tensor /= 255.\n",
    "                img_tensor = np.expand_dims(img_tensor, axis = 0)\n",
    "                \n",
    "                if isFirst:\n",
    "                    self.x_data = img_tensor\n",
    "                    isFirst = False\n",
    "                else:\n",
    "                    self.x_data = np.concatenate((x_data, img_tensor), axis=0)\n",
    "                \n",
    "                h, w, ch = image.shape\n",
    "                bytesPerLine = ch * w\n",
    "                img = QImage(image.data, w, h, bytesPerLine, QImage.Format_BGR888)\n",
    "                resizedImg = img.scaled(self.size.width(), self.size.height(), Qt.KeepAspectRatio)\n",
    "                self.sendImage.emit(resizedImg)\n",
    "            else:\n",
    "                print(\"cam read error\")\n",
    "            time.sleep(0.01) \n",
    "        print('thread finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-millennium",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
