{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 Dataset 코드에서\n",
    "\n",
    "```python\n",
    "np.save('D:/git/LipService/x_save', x_data) # x_save.npy\n",
    "np.save('D:/git/LipService/y_data', y_data) # y_data.npy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras import models, layers, activations\n",
    "from keras.layers import Conv2D, TimeDistributed, BatchNormalization, MaxPooling2D, Flatten, Bidirectional, Dense, Dropout,Flatten\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 27, 64, 64, 3) (3000, 11)\n"
     ]
    }
   ],
   "source": [
    "x_data = np.load('lip/lip_x_data.npy') # x_save.npy\n",
    "y_data = np.load('lip/lip_y_data.npy') # y_data.npy\n",
    "y_data = keras.utils.to_categorical(y_data,11)\n",
    "print(x_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (2400, 27, 64, 64, 3), X_test: (600, 27, 64, 64, 3)\n",
      "Y_train: (2400, 11), Y_test: (600, 11)\n"
     ]
    }
   ],
   "source": [
    "# Train과 Test 분리\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_data, y_data, test_size = 0.2, shuffle = True, stratify=y_data)\n",
    "#X_train = X_train / 255\n",
    "print(\"X_train: {}, X_test: {}\".format(X_train.shape, X_test.shape))\n",
    "print(\"Y_train: {}, Y_test: {}\".format(Y_train.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "class VGG_LSTM(keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VGG_LSTM, self).__init__()\n",
    "        #self.BZ = input_shape[0]\n",
    "        #self.frame = input_shape[1]\n",
    "\n",
    "        self.vgg = TimeDistributed(VGG16(weights='imagenet', include_top=False, pooling=max))\n",
    "        self.vgg.trainable = False\n",
    "\n",
    "        self.bilstm = layers.Bidirectional(layers.LSTM(256), merge_mode='concat')\n",
    "        self.dense = layers.Dense(num_classes, activation='softmax')\n",
    "        self.max_pool = TimeDistributed(MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "        self.flat= TimeDistributed(Flatten())\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.vgg(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.bilstm(x)\n",
    "        return self.dense(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_vgg():\n",
    "    return VGG_LSTM(num_classes = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_vgg()\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "#history = model.fit(X_train, Y_train, batch_size=16, epochs=5, verbose = 1, validation_data = (X_test, Y_test))\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 2346s 16s/step - loss: 2.4286 - accuracy: 0.1085 - val_loss: 2.3278 - val_accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 2309s 15s/step - loss: 2.3242 - accuracy: 0.1022 - val_loss: 2.3257 - val_accuracy: 0.1100\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 2313s 15s/step - loss: 2.3062 - accuracy: 0.1242 - val_loss: 2.2958 - val_accuracy: 0.1100\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 2309s 15s/step - loss: 2.2859 - accuracy: 0.1367 - val_loss: 2.2867 - val_accuracy: 0.1100\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 2324s 16s/step - loss: 2.2684 - accuracy: 0.1451 - val_loss: 2.2699 - val_accuracy: 0.1217\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 2306s 15s/step - loss: 2.2163 - accuracy: 0.1735 - val_loss: 2.3073 - val_accuracy: 0.1217\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 2308s 15s/step - loss: 2.2071 - accuracy: 0.1815 - val_loss: 2.2727 - val_accuracy: 0.1283\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 2308s 15s/step - loss: 2.1650 - accuracy: 0.1802 - val_loss: 2.1328 - val_accuracy: 0.2150\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 2249s 15s/step - loss: 2.0534 - accuracy: 0.2376 - val_loss: 2.0237 - val_accuracy: 0.2417\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 2150s 14s/step - loss: 1.9460 - accuracy: 0.2757 - val_loss: 1.9636 - val_accuracy: 0.2550\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 2143s 14s/step - loss: 1.8995 - accuracy: 0.2943 - val_loss: 1.9399 - val_accuracy: 0.2533\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 2205s 15s/step - loss: 1.8519 - accuracy: 0.3043 - val_loss: 1.8619 - val_accuracy: 0.2833\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 2298s 15s/step - loss: 1.7767 - accuracy: 0.3199 - val_loss: 1.8064 - val_accuracy: 0.3233\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 2238s 15s/step - loss: 1.6948 - accuracy: 0.3643 - val_loss: 1.8050 - val_accuracy: 0.3050\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 2340s 16s/step - loss: 1.6396 - accuracy: 0.3996 - val_loss: 1.8089 - val_accuracy: 0.3217\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 2324s 16s/step - loss: 1.6116 - accuracy: 0.4114 - val_loss: 1.6925 - val_accuracy: 0.3450\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 2337s 16s/step - loss: 1.5300 - accuracy: 0.4502 - val_loss: 1.6202 - val_accuracy: 0.3950\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 2318s 15s/step - loss: 1.4953 - accuracy: 0.4684 - val_loss: 1.6683 - val_accuracy: 0.3783\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 2319s 15s/step - loss: 1.4485 - accuracy: 0.4687 - val_loss: 1.6560 - val_accuracy: 0.3767\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 2320s 15s/step - loss: 1.3900 - accuracy: 0.4912 - val_loss: 1.5286 - val_accuracy: 0.4450\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 2318s 15s/step - loss: 1.3474 - accuracy: 0.4972 - val_loss: 1.5042 - val_accuracy: 0.4367\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 2357s 16s/step - loss: 1.2648 - accuracy: 0.5337 - val_loss: 1.4838 - val_accuracy: 0.4350\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 2325s 16s/step - loss: 1.2508 - accuracy: 0.5490 - val_loss: 1.4584 - val_accuracy: 0.4617\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 2323s 16s/step - loss: 1.2283 - accuracy: 0.5685 - val_loss: 1.4821 - val_accuracy: 0.4617\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 2316s 15s/step - loss: 1.2138 - accuracy: 0.5723 - val_loss: 1.4449 - val_accuracy: 0.4667\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 2313s 15s/step - loss: 1.1712 - accuracy: 0.5876 - val_loss: 1.3656 - val_accuracy: 0.5250\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 2332s 16s/step - loss: 1.0671 - accuracy: 0.6244 - val_loss: 1.4002 - val_accuracy: 0.4933\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 2320s 15s/step - loss: 1.1050 - accuracy: 0.5887 - val_loss: 1.3211 - val_accuracy: 0.5067\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 2389s 16s/step - loss: 1.0393 - accuracy: 0.6255 - val_loss: 1.2863 - val_accuracy: 0.5450\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 2336s 16s/step - loss: 1.0301 - accuracy: 0.6392 - val_loss: 1.3288 - val_accuracy: 0.5167\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 2446s 16s/step - loss: 0.9894 - accuracy: 0.6405 - val_loss: 1.3791 - val_accuracy: 0.5050\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 2342s 16s/step - loss: 0.9569 - accuracy: 0.6533 - val_loss: 1.3148 - val_accuracy: 0.5400\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 2379s 16s/step - loss: 0.9623 - accuracy: 0.6665 - val_loss: 1.3257 - val_accuracy: 0.5133\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 2329s 16s/step - loss: 0.9305 - accuracy: 0.6767 - val_loss: 1.3190 - val_accuracy: 0.5333\n",
      "Epoch 35/100\n",
      " 15/150 [==>...........................] - ETA: 28:56 - loss: 1.0756 - accuracy: 0.5893"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "history = model.fit(X_train, Y_train, batch_size=16, epochs=100, verbose = 1, validation_split=0.2, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
